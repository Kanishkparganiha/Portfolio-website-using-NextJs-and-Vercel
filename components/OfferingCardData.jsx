const OfferingCardData = [
  {
    img: 'bert-google.png',
    title: 'Python',
    Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset using PyTorch',
    Typography_H2: 'PyTorch | BERT | RNN | Transformers',
    Typography_p: "In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem"
    ,link:'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'
  },
  {
    img: 'Python.png',
    title: 'Python',
    Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset using PyTorch',
    Typography_H2: 'PyTorch, BERT, Pre-Trained Model',
    Typography_p: "In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem"
   ,link:'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'
  },
  {
    img: 'Python.png',
    title: 'Python',
    Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset using PyTorch',
    Typography_H2: 'PyTorch, BERT, Pre-Trained Model',
    Typography_p: "In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem"
    ,link:'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'
  },
  {
    img: 'Python.png',
    title: 'Python',
    Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset using PyTorch',
    Typography_H2: 'PyTorch, BERT, Pre-Trained Model',
    Typography_p: "In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem"
    ,link:'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'
  }

];

export default OfferingCardData;
