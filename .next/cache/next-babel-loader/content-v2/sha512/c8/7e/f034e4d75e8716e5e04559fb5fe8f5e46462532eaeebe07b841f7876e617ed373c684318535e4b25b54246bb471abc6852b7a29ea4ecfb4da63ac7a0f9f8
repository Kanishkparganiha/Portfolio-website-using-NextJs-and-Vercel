{"ast":null,"code":"var OfferingCardData = [{\n  img: 'bert-google.png',\n  title: 'Python',\n  Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset for Named Entity Recognition using PyTorch',\n  Typography_H2: 'PyTorch | BERT | RNN | Transformers',\n  Typography_p: \"In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem\",\n  link: 'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'\n}, {\n  img: 'CNN.png',\n  title: 'Python',\n  Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset using PyTorch',\n  Typography_H2: 'PyTorch | CNN | CIFAR-10 | Deep Learning',\n  Typography_p: \"In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem\",\n  link: 'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'\n}];\nexport default OfferingCardData;","map":{"version":3,"sources":["/home/kanishka/data_science/Portfolio-website-using-NextJs-and-Vercel/components/OfferingCardData.jsx"],"names":["OfferingCardData","img","title","Typography_H1","Typography_H2","Typography_p","link"],"mappings":"AAAA,IAAMA,gBAAgB,GAAG,CACvB;AACEC,EAAAA,GAAG,EAAE,iBADP;AAEEC,EAAAA,KAAK,EAAE,QAFT;AAGEC,EAAAA,aAAa,EAAE,oFAHjB;AAIEC,EAAAA,aAAa,EAAE,qCAJjB;AAKEC,EAAAA,YAAY,EAAE,qSALhB;AAMGC,EAAAA,IAAI,EAAC;AANR,CADuB,EASvB;AACEL,EAAAA,GAAG,EAAE,SADP;AAEEC,EAAAA,KAAK,EAAE,QAFT;AAGEC,EAAAA,aAAa,EAAE,uDAHjB;AAIEC,EAAAA,aAAa,EAAE,0CAJjB;AAKEC,EAAAA,YAAY,EAAE,qSALhB;AAMEC,EAAAA,IAAI,EAAC;AANP,CATuB,CAAzB;AAmBA,eAAeN,gBAAf","sourcesContent":["const OfferingCardData = [\n  {\n    img: 'bert-google.png',\n    title: 'Python',\n    Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset for Named Entity Recognition using PyTorch',\n    Typography_H2: 'PyTorch | BERT | RNN | Transformers',\n    Typography_p: \"In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem\"\n    ,link:'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'\n  },\n  {\n    img: 'CNN.png',\n    title: 'Python',\n    Typography_H1: 'Fine-Tuning BERT model on CoNLL dataset using PyTorch',\n    Typography_H2: 'PyTorch | CNN | CIFAR-10 | Deep Learning',\n    Typography_p: \"In this work I proposed pretraining larger Transformer based Encode-Decoder models on massive text corpora of MIT movie dataset by adding a token-level classifier on the top of the BERT model. We will then evaluate our model using F-1 score as this problem is typically a multi-class problem\"\n   ,link:'https://github.com/Kanishkparganiha/Named-Entity-Recognition-using-BERT-with-PyTorch'\n  }\n];\n\nexport default OfferingCardData;\n"]},"metadata":{},"sourceType":"module"}